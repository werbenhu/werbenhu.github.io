<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>werbenhu的个人博客</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">werbenhu的个人博客</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="go-syncmap源码解读"><a class="header" href="#go-syncmap源码解读">Go sync.Map源码解读</a></h1>
<h2 id="内置的map"><a class="header" href="#内置的map">内置的map</a></h2>
<p>Go 的内置的 map 是不支持并发写操作的，不是并发安全的。</p>
<p>看下面的代码运行会提示</p>
<p><code>fatal error: concurrent map writes。</code></p>
<pre><code class="language-go">package main

import "time"

var globleMap map[string]interface{}

func MapEdit(key string) {
	for i := 0; i &lt; 10000; i++ {
		globleMap[key] = i
	}
}

func main() {
	globleMap = make(map[string]interface{})
	go MapEdit("1")
	go MapEdit("2")
	time.Sleep(time.Second * 30)
}
</code></pre>
<p>因此官方在go 1.9版本中给了 sync.Map来满足并发编程中的应用。</p>
<p>这里实际上是一个lock-free，关于lock-free和wait-free可以看看这里：<a href="https://www.zhihu.com/question/295904223">wait-free是指什么?</a></p>
<h2 id="syncmap"><a class="header" href="#syncmap">sync.Map</a></h2>
<p>sync.Map 的实现原理可概括为：</p>
<p>read和dirty
我们可以这么理解，现在将map里面的数据分成两部分保存，我用两个桶来比喻，</p>
<ul>
<li>一些是干净(read)的，放在白桶</li>
<li>一些是脏(dirty)的，放在脏桶，我这也叫黑桶</li>
</ul>
<p>另外我还要记录一下，这个脏的程度，怎么判断脏的程度呢，这里我用一个脏值(<code>misses</code>)来标识脏的程度，每次读数据时发现有一个数据(<code>key</code>)不在白桶而是在黑桶，我就将脏值数量(<code>misses</code>)+1，如果发现脏值(<code>misses</code>)居然比黑桶(<code>read</code>)里的数据总数量还多，那就得清洗一下黑桶(<code>dirty</code>)里面的数据了，将清洗完的脏(<code>dirty</code>)数据全部放到白桶(<code>read</code>)那里去，这时候黑桶所有的数据(<code>dirty</code>)被清空了，脏值(misses)也要重置为0</p>
<p>白桶里面还贴了一个字条(<code>amended</code>: 英文释义修正的，改正的)，这个字条表示黑桶是不是刚刚被清洗收拾，因为黑桶不是一直被收拾的，每次当黑桶被收拾，脏值清空的时候，这个字条就写上“已收拾”（<code>amended=false</code>）。</p>
<h3 id="写数据"><a class="header" href="#写数据">写数据</a></h3>
<ul>
<li>数据在白桶里</li>
</ul>
<p>一个新的数据key要保存到map里面，首先先查一下这个数据(key)是不是已经在白桶里面，如果数据在白桶里面，直接更新这个数据就行了。</p>
<ul>
<li>数据在黑桶里</li>
</ul>
<p>如果这个数据(key)不在白桶里(read)，字条还写着“欠收拾”那数据就有可能在黑桶(dirty)里，如果在黑桶(dirty)里找到了，更新这个黑桶(dirty)里面的数据(key)，同时更新下脏值(misses)+1，接下来还要判断下脏值的数据量不是已经比白桶(read)里面数据总量还大，如果是，那就得清洗下黑桶(dirty)里面的数据</p>
<ul>
<li>数据即不在白桶里，也不在黑桶里</li>
</ul>
<p>数据既不在白桶，也不在黑桶，要分两种情况</p>
<p>白条写着“已收拾”，说明黑桶恰巧刚刚被收拾了，那么现在重新将白桶里面所有的数据又复制一份放到黑桶里面去，白桶里面字条改成“欠收拾”（<code>amended=true</code>)，然后直接写入数据到黑桶
白桶里面写着“欠收拾”，说明黑桶里面有脏数据，但是又没到收拾他的时候，直接写入数据到黑桶</p>
<h3 id="读数据"><a class="header" href="#读数据">读数据</a></h3>
<ul>
<li>数据在白桶</li>
</ul>
<p>直接从白桶取数据</p>
<ul>
<li>数据不在白桶，白条写着“欠收拾”</li>
</ul>
<p>说明黑桶有白桶不存在的数据，数据可能在黑桶，从黑桶取数据，如果key数据存在，脏值+1，判断是否需要清洗黑桶</p>
<ul>
<li>数据不在白桶，黑桶也找不到</li>
</ul>
<p>数据不存在，返回nil</p>
<h4 id="用法问题"><a class="header" href="#用法问题">用法问题</a></h4>
<p>看下面的示例，写入<code>map</code>1000个<code>key</code>，但是读取只读了900次<code>key</code>，</p>
<p>这时候根本白桶的数据始终都会是空的，因为黑桶只有脏值到了1000才会将数据清洗到白桶。</p>
<p>也就是这种情况，可能效率还没有自己写的使用内置的<code>map</code>，加锁的效率高。</p>
<p>所以<em>sync.map适合少量写，大量读的场景</em></p>
<pre><code class="language-go">package main

import (
	"math/rand"
	"testgorm/mymap"
	"time"
)

func main() {
	var m mymap.Map
	//写入1000个key，这时黑桶数据数量是1000
	for i := 0; i &lt; 1000; i++ {
		rand.Seed(time.Now().UnixNano())
		data := rand.Intn(1000)
		m.Store(i, data)
	}
	//读取900次key，这时候脏值为900 &lt; 黑桶数据数量
  //白桶的数据一直都是空的，因为黑桶一直没到清洗的条件
	for i := 0; i &lt; 900; i++ {
		if _, ok := m.Load(i); ok {
		}
	}
}
</code></pre>
<h2 id="源码阅读"><a class="header" href="#源码阅读">源码阅读</a></h2>
<pre><code class="language-go">package mymap

import (
	"fmt"
	"sync"
	"sync/atomic"
	"unsafe"
)

type Map struct {
	//用来锁dirty
	mu sync.Mutex
	//白桶
	read atomic.Value
	//黑桶
	dirty map[interface{}]*entry
	//脏值
	misses int
}

type readOnly struct {
	//封装的map
	m map[interface{}]*entry
	//白条
	amended bool
}

//expunged是一个指针指向一个空对象，也就是指向interface{}
var expunged = unsafe.Pointer(new(interface{}))

//entry就是一个指针
type entry struct {
	p unsafe.Pointer
}

func newEntry(i interface{}) *entry {
	return &amp;entry{p: unsafe.Pointer(&amp;i)}
}

//从sync.map读数据
func (m *Map) Load(key interface{}) (value interface{}, ok bool) {
	//先看白桶里面有没有key
	read, _ := m.read.Load().(readOnly)
	//有则直接返回
	e, ok := read.m[key]
	//如果白桶里没有这个key，而且白条写着“欠收拾”，说明黑桶里面可能有key
	if !ok &amp;&amp; read.amended {
		m.mu.Lock()
		//上面白桶获取时没有加锁，上锁后再检查一次
		read, _ = m.read.Load().(readOnly)
		e, ok = read.m[key]
		//再检查一次也没有，则直接从黑桶里面读取数据
		if !ok &amp;&amp; read.amended {
			e, ok = m.dirty[key]
            //脏值+1, 如果脏值比黑桶数据数量还大，则收拾黑桶
			m.missLocked()
		}
		m.mu.Unlock()
	}
	//如果白桶黑桶里都没有数据，返回nil
	if !ok {
		return nil, false
	}
	//返回entry指针对应的值
	return e.load()
}

//获取entry指针对应的值
func (e *entry) load() (value interface{}, ok bool) {
	p := atomic.LoadPointer(&amp;e.p)
	if p == nil || p == expunged {
		return nil, false
	}
	return *(*interface{})(p), true
}

//往sync.map写数据
func (m *Map) Store(key, value interface{}) {
	//先看白桶里面有没有key
	read, _ := m.read.Load().(readOnly)
	//白桶存在key直接更新白桶里面的数据
	if e, ok := read.m[key]; ok &amp;&amp; e.tryStore(&amp;value) {
		return
	}

	m.mu.Lock()
	//上面白桶获取没有加锁，上锁后再写入一次白桶
	read, _ = m.read.Load().(readOnly)
	if e, ok := read.m[key]; ok {
		if e.unexpungeLocked() {
			//白桶存在key直接更新白桶里面的数据
			m.dirty[key] = e
		}
		//将黑桶里面的key也指向value，相当于黑桶和白桶都指向同一份数据
		e.storeLocked(&amp;value)
	} else if e, ok := m.dirty[key]; ok {
		//如果白桶里面没有这个key，但是黑桶里面有，直接更新黑桶里面的数据
		e.storeLocked(&amp;value)
	} else {
		//白桶和黑桶都没有这个key
		if !read.amended {
			//如果黑桶刚刚被收拾过，白条“已收拾”，则需要将白桶里的数据，复制一份到黑桶
			m.dirtyLocked()
			//设置白条为“欠收拾”
			m.read.Store(readOnly{m: read.m, amended: true})
		}
		//将新数据丢到黑桶
		m.dirty[key] = newEntry(value)
	}
	m.mu.Unlock()
}

//tryStore就是一个基于CAS的原子写操作
func (e *entry) tryStore(i *interface{}) bool {
	for {
		p := atomic.LoadPointer(&amp;e.p)
		//如果原先key对应的值是一个interface{}空对象，返回失败
		if p == expunged {
			return false
		}
		//CAS原子写入entity
		if atomic.CompareAndSwapPointer(&amp;e.p, p, unsafe.Pointer(i)) {
			return true
		}
	}
}

//判断entry是否=expunged（interface{}）,如果是将entry设置为nil
func (e *entry) unexpungeLocked() (wasExpunged bool) {
	return atomic.CompareAndSwapPointer(&amp;e.p, expunged, nil)
}

//原子写入entry
func (e *entry) storeLocked(i *interface{}) {
	atomic.StorePointer(&amp;e.p, unsafe.Pointer(i))
}

//参照Store
func (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool) {
	read, _ := m.read.Load().(readOnly)
	if e, ok := read.m[key]; ok {
		actual, loaded, ok := e.tryLoadOrStore(value)
		if ok {
			return actual, loaded
		}
	}

	m.mu.Lock()
	read, _ = m.read.Load().(readOnly)
	if e, ok := read.m[key]; ok {
		if e.unexpungeLocked() {
			m.dirty[key] = e
		}
		actual, loaded, _ = e.tryLoadOrStore(value)
	} else if e, ok := m.dirty[key]; ok {
		actual, loaded, _ = e.tryLoadOrStore(value)
		m.missLocked()
	} else {
		if !read.amended {
			m.dirtyLocked()
			m.read.Store(readOnly{m: read.m, amended: true})
		}
		m.dirty[key] = newEntry(value)
		actual, loaded = value, false
	}
	m.mu.Unlock()

	return actual, loaded
}

func (e *entry) tryLoadOrStore(i interface{}) (actual interface{}, loaded, ok bool) {
	p := atomic.LoadPointer(&amp;e.p)
	if p == expunged {
		return nil, false, false
	}
	if p != nil {
		return *(*interface{})(p), true, true
	}

	ic := i
	for {
		if atomic.CompareAndSwapPointer(&amp;e.p, nil, unsafe.Pointer(&amp;ic)) {
			return i, false, true
		}
		p = atomic.LoadPointer(&amp;e.p)
		if p == expunged {
			return nil, false, false
		}
		if p != nil {
			return *(*interface{})(p), true, true
		}
	}
}

func (m *Map) Delete(key interface{}) {
	read, _ := m.read.Load().(readOnly)
	//数据在白桶，直接删除白桶里面的数据
	e, ok := read.m[key]
	if !ok &amp;&amp; read.amended {
		m.mu.Lock()
		read, _ = m.read.Load().(readOnly)
		e, ok = read.m[key]
		//数据不在白桶，黑桶“欠收拾”
		if !ok &amp;&amp; read.amended {
			//直接黑桶清除数据
			delete(m.dirty, key)
		}
		m.mu.Unlock()
	}
	if ok {
		e.delete()
	}
}

func (e *entry) delete() (hadValue bool) {
	for {
		p := atomic.LoadPointer(&amp;e.p)
		if p == nil || p == expunged {
			return false
		}
		if atomic.CompareAndSwapPointer(&amp;e.p, p, nil) {
			return true
		}
	}
}

func (m *Map) Range(f func(key, value interface{}) bool) {
	read, _ := m.read.Load().(readOnly)
	if read.amended {
		m.mu.Lock()
		read, _ = m.read.Load().(readOnly)
		if read.amended {
			read = readOnly{m: m.dirty}
			m.read.Store(read)
			m.dirty = nil
			m.misses = 0
		}
		m.mu.Unlock()
	}

	for k, e := range read.m {
		v, ok := e.load()
		if !ok {
			continue
		}
		if !f(k, v) {
			break
		}
	}
}

//脏值+1,
func (m *Map) missLocked() {
    //脏值+1,
	m.misses++
    //如果脏值比黑桶数据数量还大，则收拾黑桶
	if m.misses &lt; len(m.dirty) {
		return
	}
	m.read.Store(readOnly{m: m.dirty})
	//将黑桶map清空
	m.dirty = nil
	//将脏值清零
	m.misses = 0
}

func (m *Map) dirtyLocked() {
	if m.dirty != nil {
		return
	}

	//黑桶已经被清洗过了，这里要重新初始化黑桶
	read, _ := m.read.Load().(readOnly)
	m.dirty = make(map[interface{}]*entry, len(read.m))
    //将白桶里面的复制一份到黑桶
	for k, e := range read.m {
		if !e.tryExpungeLocked() {
			m.dirty[k] = e
		}
	}
}

//这里就是判断entry是不是指向空对象或者是nil
//如果entry=是nil，赋值为空对象,也返回true
func (e *entry) tryExpungeLocked() (isExpunged bool) {
	p := atomic.LoadPointer(&amp;e.p)
	for p == nil {
		//如果entry指向nil，给entry赋值空对象interface{},返回true
		if atomic.CompareAndSwapPointer(&amp;e.p, nil, expunged) {
			return true
		}
		p = atomic.LoadPointer(&amp;e.p)
	}
	return p == expunged
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="nsq源码-diskqueue"><a class="header" href="#nsq源码-diskqueue">nsq源码-diskqueue</a></h1>
<p>channel有下面几个重要的成员，其实跟topic还有点像，都有一个memoryMsgChan和diskqueue</p>
<ol>
<li>
<p><strong>memoryMsgChan</strong>： 这是存放消息的内存，就是一个通道，通道的大小MemQueueSize，
默认配置是10000，也就是如果堆积的消息超过10000就会使用磁盘了</p>
</li>
<li>
<p><strong>backend</strong> ：就是diskqueue，这个就是磁盘存储消息的地方了，关于这个diskqueue，请参考：https://www.cnblogs.com/werben/p/14517781.html</p>
</li>
<li>
<p><strong>clients</strong> ： Consumer 这里关联的是客户端的订阅者</p>
</li>
<li>
<p><strong>deferredMessages和deferredPQ</strong> ： 延迟消息存放的地方，其中deferredPQ，是一个优先级管理的队列，直接丢在内存</p>
</li>
<li>
<p><strong>inFlightMessages和inFlightPQ</strong>: 这个标识正在执行中的消息，也是直接丢在内存</p>
</li>
</ol>
<p>topic在messagePump()中处理消息的时候，通过下面两个函数，将消息投递到channel。</p>
<pre><code>//延时消息
channel.PutMessageDeferred(chanMsg, chanMsg.deferred)
//非延时消息
channel.PutMessage(chanMsg)
</code></pre>
<p>在这里我们看不到Channel的“守护”协程，也就是我们只看到topic将msg投递到channel，channel将延时消息丢到队列中，但是找不到channel从队列中取出数据发送给client consumer的地方</p>
<p>找到channel的两个函数, 看了下就是这两个函数将msg发送给client consumer的</p>
<pre><code>func (c *Channel) processDeferredQueue(t int64) bool
func (c *Channel) processInFlightQueue(t int64) bool
</code></pre>
<p>但是channel本身没有“守护”协程，一直运行来调用这两个函数，找这两个函数调用的地方，一直往上找调用者。最终找到“守护”协程在哪里了。</p>
<p>原来在nsqd里面运行了一个queueScanLoop的“守护”协程。</p>
<h2 id="一nsqdqueuescanloop"><a class="header" href="#一nsqdqueuescanloop">一、nsqd.queueScanLoop</a></h2>
<pre><code class="language-go">//nsqd.go

func (n *NSQD) queueScanLoop() {
	workCh := make(chan *Channel, n.getOpts().QueueScanSelectionCount)
	responseCh := make(chan bool, n.getOpts().QueueScanSelectionCount)
	closeCh := make(chan int)

	//定时执行loop的间隔时间，默认100ms
	workTicker := time.NewTicker(n.getOpts().QueueScanInterval)
	//刷新channel数量，重新调整协程池，默认时间是5s刷新一次
	refreshTicker := time.NewTicker(n.getOpts().QueueScanRefreshInterval)

	channels := n.channels()
	n.resizePool(len(channels), workCh, responseCh, closeCh)

	for {
		select {
		case &lt;-workTicker.C:
			if len(channels) == 0 {
				continue
			}
		case &lt;-refreshTicker.C:
			channels = n.channels()
			n.resizePool(len(channels), workCh, responseCh, closeCh)
			continue
		case &lt;-n.exitChan:
			goto exit
		}

		num := n.getOpts().QueueScanSelectionCount
		if num &gt; len(channels) {
			num = len(channels)
		}

	loop:
		//从 channels 中随机选择 num 个 channel
		for _, i := range util.UniqRands(num, len(channels)) {
			workCh &lt;- channels[i]
		}

		//等待处理响应，记录失败次数
		numDirty := 0
		for i := 0; i &lt; num; i++ {
			if &lt;-responseCh {
				numDirty++
			}
		}

		//queueScanLoop的处理方法模仿了Redis的概率到期算法
		//(probabilistic expiration algorithm)，
		//每过一个QueueScanInterval(默认100ms)间隔，进行一次概率选择，
		//从所有的channel缓存中随机选择QueueScanSelectionCount(默认20)个channel，
		//如果某个被选中channel存在InFlighting消息或者Deferred消息，
		//则认为该channel为“脏”channel。
		//如果被选中channel中“脏”channel的比例大于QueueScanDirtyPercent(默认25%)，
		//则不投入睡眠，直接进行下一次概率选择
		if float64(numDirty)/float64(num) &gt; n.getOpts().QueueScanDirtyPercent {
			goto loop
		}
	}

exit:
	n.logf(LOG_INFO, "QUEUESCAN: closing")
	close(closeCh)
	workTicker.Stop()
	refreshTicker.Stop()
}

//协程池调整
func (n *NSQD) resizePool(num int, workCh chan *Channel, responseCh chan bool, closeCh chan int) {

	// 协程池大小 = 总channel数 / 4
	idealPoolSize := int(float64(num) * 0.25)
	if idealPoolSize &lt; 1 {
		idealPoolSize = 1
	} else if idealPoolSize &gt; n.getOpts().QueueScanWorkerPoolMax {
		//idealPoolSize 协程池大小，最大默认是4个
		idealPoolSize = n.getOpts().QueueScanWorkerPoolMax
	}
	for {
		if idealPoolSize == n.poolSize {
			break
		} else if idealPoolSize &lt; n.poolSize {
			// contract
			// 协程池协程容量 &lt; 当前已经开启的协程数量
			// 说明开启的协程过多，需要关闭协程
			// closeCh queueScanWorker会中断“守护”协程
			// 关闭后，将当前开启的协程数量-1
			closeCh &lt;- 1
			n.poolSize--
		} else {
			// expand
			// 协程池协程容量 &gt; 当前已经开启的协程数量
			// 开启新的协程
			n.waitGroup.Wrap(func() {
				n.queueScanWorker(workCh, responseCh, closeCh)
			})
			n.poolSize++
		}
	}
}

// 真正调用channel.processInFlightQueue的地方
func (n *NSQD) queueScanWorker(workCh chan *Channel, responseCh chan bool, closeCh chan int) {
	for {
		select {
		case c := &lt;-workCh:
			//处理一次某个channel的消息
			now := time.Now().UnixNano()
			dirty := false
			if c.processInFlightQueue(now) {
				dirty = true
			}
			if c.processDeferredQueue(now) {
				dirty = true
			}
			//如果这个channel有消息，则设置为dirty=true
			responseCh &lt;- dirty
		case &lt;-closeCh:
			return
		}
	}
}
</code></pre>
<h2 id="二channelprocessinflightqueue"><a class="header" href="#二channelprocessinflightqueue">二、channel.processInFlightQueue</a></h2>
<p>现在搞清楚了processInFlightQueue调用的地方，那这个processInFlightQueue到底做了什么</p>
<pre><code class="language-go">func (c *Channel) processInFlightQueue(t int64) bool {
	c.exitMutex.RLock()
	defer c.exitMutex.RUnlock()

	if c.Exiting() {
		return false
	}

	dirty := false
	for {
		c.inFlightMutex.Lock()
		msg, _ := c.inFlightPQ.PeekAndShift(t)
		c.inFlightMutex.Unlock()

		if msg == nil {
			goto exit
		}

		//只要有消息就标识这个通道是脏的
		dirty = true

		_, err := c.popInFlightMessage(msg.clientID, msg.ID)
		if err != nil {
			goto exit
		}
		atomic.AddUint64(&amp;c.timeoutCount, 1)
		c.RLock()
		client, ok := c.clients[msg.clientID]
		c.RUnlock()
		if ok {
			client.TimedOutMessage()
		}
		//循环将channel中存在inFlightPQ中消息put出去
		//put到memoryMsgChan或者磁盘
		c.put(msg)
	}

exit:
	return dirty
}

func (c *Channel) put(m *Message) error {
	select {
	//将消息写入到memoryMsgChan中去
	case c.memoryMsgChan &lt;- m:
	//如果memoryMsgChan满了则将消息写到磁盘中区
	default:
		err := writeMessageToBackend(m, c.backend)
		c.nsqd.SetHealth(err)
		if err != nil {
			c.nsqd.logf(LOG_ERROR, "CHANNEL(%s): failed to write message to backend - %s",
				c.name, err)
			return err
		}
	}
	return nil
}
</code></pre>
<h2 id="三channelprocessdeferredqueue"><a class="header" href="#三channelprocessdeferredqueue">三、channel.processDeferredQueue</a></h2>
<p>接下来看看延时消息是怎么处理的
延时消息看起来跟非延时消息没什么区别
其实是有区别的，区别就在c.deferredPQ.PeekAndShift(t)这里</p>
<pre><code class="language-go">func (c *Channel) processDeferredQueue(t int64) bool {
	c.exitMutex.RLock()
	defer c.exitMutex.RUnlock()

	if c.Exiting() {
		return false
	}

	dirty := false
	for {
		c.deferredMutex.Lock()
		//区别在这个PeekAndShift里面
		item, _ := c.deferredPQ.PeekAndShift(t)
		c.deferredMutex.Unlock()

		if item == nil {
			goto exit
		}
		dirty = true

		msg := item.Value.(*Message)
		_, err := c.popDeferredMessage(msg.ID)
		if err != nil {
			goto exit
		}
		//put到memoryMsgChan或者磁盘
		c.put(msg)
	}

exit:
	return dirty
}

//pqueue.go 
//max实参传入的是当前时间
func (pq *PriorityQueue) PeekAndShift(max int64) (*Item, int64) {
	if pq.Len() == 0 {
		return nil, 0
	}

	item := (*pq)[0]
	//存入延时消息时，Priority优先级就是消息的到期时间
	//这里只有当前时间大于了消息的到期时间才回返回
	if item.Priority &gt; max {
		return nil, item.Priority - max
	}
	heap.Remove(pq, 0)

	return item, 0
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="nsq源码-diskqueue-1"><a class="header" href="#nsq源码-diskqueue-1">nsq源码-diskqueue</a></h1>
<p>有兴趣可以看看这篇文章
https://www.cnblogs.com/zhangboyu/p/7457070.html</p>
<h2 id="一队列存储"><a class="header" href="#一队列存储">一、队列存储</a></h2>
<p>队列的特征是先入先出，也就是写入是从后面写入，读取是从前面读取
我们平时写的队列一般是放到内存里面，比如一个大的动态数组
这里如果队列中的数据很大，diskqueue则是将这个动态数组拆成了好多个文件来存储队列中的数据</p>
<p>如果队列是放在内存数组中，那么队列只需要记录两个属性，一个头的位置，一个是尾的位置，
队列大小depth = 头位置 - 尾位置</p>
<p>但是由于diskqueue是将数组保存在多个文件中
所以diskqueue就会有五个属性： 头所在的文件，头在文件中的位置，尾所在的文件，尾在文件中的位置，还有就是depth标识头和尾中间的数据数量
这五个数据作为diskqueue的元数据单独保存在一个文件里面。
所以New一个diskqueue的时候先要这几个元数据读取出来</p>
<pre><code class="language-go">func New(name string, dataPath string, maxBytesPerFile int64,
	minMsgSize int32, maxMsgSize int32,
	syncEvery int64, syncTimeout time.Duration, logf AppLogFunc) Interface {
	d := diskQueue{
		//名称
		name:              name,
		//文件保存路径
		dataPath:          dataPath,
		//每个文件大小最大值，超过要重新开启一个文件
		maxBytesPerFile:   maxBytesPerFile,
		//写入消息最小大小
		minMsgSize:        minMsgSize,
		//写入消息最大大小
		maxMsgSize:        maxMsgSize,
		readChan:          make(chan []byte),
		writeChan:         make(chan []byte),
		writeResponseChan: make(chan error),
		emptyChan:         make(chan int),
		emptyResponseChan: make(chan error),
		exitChan:          make(chan int),
		exitSyncChan:      make(chan int),
		syncEvery:         syncEvery,
		syncTimeout:       syncTimeout,
		logf:              logf,
	}

	// 读取队列数据
	err := d.retrieveMetaData()
	if err != nil &amp;&amp; !os.IsNotExist(err) {
		d.logf(ERROR, "DISKQUEUE(%s) failed to retrieveMetaData - %s", d.name, err)
	}

	go d.ioLoop()
	return &amp;d
}

// 读取队列数据
func (d *diskQueue) retrieveMetaData() error {
	var f *os.File
	var err error

	fileName := d.metaDataFileName()
	f, err = os.OpenFile(fileName, os.O_RDONLY, 0600)
	if err != nil {
		return err
	}
	defer f.Close()

	//队列写入和读取位置中间有多少条数据，也就是队列的大小
	var depth int64
	//读取队列核心数据
	//当前读取文件是哪个，读取位置是哪里
	//当前写入的文件是哪个，写入文件位置
	_, err = fmt.Fscanf(f, "%d\n%d,%d\n%d,%d\n",
		&amp;depth,
		&amp;d.readFileNum, &amp;d.readPos,
		&amp;d.writeFileNum, &amp;d.writePos)
	if err != nil {
		return err
	}
	atomic.StoreInt64(&amp;d.depth, depth)

	//下一个读取文件
	d.nextReadFileNum = d.readFileNum
	//下一个读取位置
	d.nextReadPos = d.readPos

	return nil
}
</code></pre>
<h2 id="二写入队列"><a class="header" href="#二写入队列">二、写入队列</a></h2>
<pre><code class="language-go">func (d *diskQueue) writeOne(data []byte) error {
	var err error

	// 当前写入文件是否打开，没有则打开当前写入文件
	if d.writeFile == nil {
		curFileName := d.fileName(d.writeFileNum)
		d.writeFile, err = os.OpenFile(curFileName, os.O_RDWR|os.O_CREATE, 0600)
		if err != nil {
			return err
		}

		d.logf(INFO, "DISKQUEUE(%s): writeOne() opened %s", d.name, curFileName)

		//如果当前写入位置大于0，则将文件位置移动到写入位置点
		if d.writePos &gt; 0 {
			_, err = d.writeFile.Seek(d.writePos, 0)
			if err != nil {
				d.writeFile.Close()
				d.writeFile = nil
				return err
			}
		}
	}

	dataLen := int32(len(data))

	//判断消息大小是否合法
	if dataLen &lt; d.minMsgSize || dataLen &gt; d.maxMsgSize {
		return fmt.Errorf("invalid message write size (%d) maxMsgSize=%d", dataLen, d.maxMsgSize)
	}

	//将缓冲区清空
	d.writeBuf.Reset()
	//将消息大小写入缓冲区
	err = binary.Write(&amp;d.writeBuf, binary.BigEndian, dataLen)
	if err != nil {
		return err
	}

	//将消息写入缓冲区
	_, err = d.writeBuf.Write(data)
	if err != nil {
		return err
	}

	// only write to the file once
	//将缓冲区关联到文件
	_, err = d.writeFile.Write(d.writeBuf.Bytes())
	if err != nil {
		d.writeFile.Close()
		d.writeFile = nil
		return err
	}

	//计算总大小
	totalBytes := int64(4 + dataLen)
	d.writePos += totalBytes
	//队列消息数量+1
	atomic.AddInt64(&amp;d.depth, 1)

	//如果写入位置大于了文件最大大小
	if d.writePos &gt;= d.maxBytesPerFile {
		//将当前写入文件+1
		d.writeFileNum++
		//当前写入位置重置为0
		d.writePos = 0

		// sync every time we start writing to a new file
		//将缓存数据写入到磁盘
		err = d.sync()
		if err != nil {
			d.logf(ERROR, "DISKQUEUE(%s) failed to sync - %s", d.name, err)
		}

		if d.writeFile != nil {
			d.writeFile.Close()
			d.writeFile = nil
		}
	}

	return err
}
</code></pre>
<h2 id="读取队列"><a class="header" href="#读取队列">读取队列</a></h2>
<pre><code class="language-go">func (d *diskQueue) readOne() ([]byte, error) {
	var err error
	var msgSize int32

	// 当前读取文件是否打开，没有则打开当前文件
	if d.readFile == nil {
		// 打开读取的文件（也就是当前队列头所在的文件），如果文件大小到达上线maxBytesPerFile，readFileNum加一
		curFileName := d.fileName(d.readFileNum)
		d.readFile, err = os.OpenFile(curFileName, os.O_RDONLY, 0600)
		if err != nil {
			return nil, err
		}

		d.logf(INFO, "DISKQUEUE(%s): readOne() opened %s", d.name, curFileName)

		//当前队列头在当前读取文件的位置
		if d.readPos &gt; 0 {
			_, err = d.readFile.Seek(d.readPos, 0)
			if err != nil {
				d.readFile.Close()
				d.readFile = nil
				return nil, err
			}
		}

		d.reader = bufio.NewReader(d.readFile)
	}

	// 先读取出消息的大小
	err = binary.Read(d.reader, binary.BigEndian, &amp;msgSize)
	if err != nil {
		d.readFile.Close()
		d.readFile = nil
		return nil, err
	}

	//判断消息大小是否合法
	if msgSize &lt; d.minMsgSize || msgSize &gt; d.maxMsgSize {
		// this file is corrupt and we have no reasonable guarantee on
		// where a new message should begin
		d.readFile.Close()
		d.readFile = nil
		return nil, fmt.Errorf("invalid message read size (%d)", msgSize)
	}

	//读取消息
	readBuf := make([]byte, msgSize)
	_, err = io.ReadFull(d.reader, readBuf)
	if err != nil {
		d.readFile.Close()
		d.readFile = nil
		return nil, err
	}

	totalBytes := int64(4 + msgSize)

	//将下一个要读取的位置往后移
	d.nextReadPos = d.readPos + totalBytes
	d.nextReadFileNum = d.readFileNum

	//判断下一个读取的位置是不是超过了文件大小
	if d.nextReadPos &gt; d.maxBytesPerFile {
		if d.readFile != nil {
			d.readFile.Close()
			d.readFile = nil
		}
		//如果超过了，则当前队列头文件要往后移，且读取位置设置为0
		d.nextReadFileNum++
		d.nextReadPos = 0
	}

	return readBuf, nil
}
</code></pre>
<pre><code class="language-go">// 刷新缓存到磁盘
func (d *diskQueue) sync() error {
	if d.writeFile != nil {
		// 将缓冲区的数据从内存中拷贝刷新到硬盘中保存
		err := d.writeFile.Sync()
		if err != nil {
			d.writeFile.Close()
			d.writeFile = nil
			return err
		}
	}

	//保存元数据
	err := d.persistMetaData()
	if err != nil {
		return err
	}

	d.needSync = false
	return nil
}
</code></pre>
<p>五、ioLoop循环</p>
<p>这个函数是一个“守护”协程，
暴露的d.writeChan和d.readChan
如果外部有网writeChan里写数据在这里处理
同时，这里的消息也会通过d.readChan将消息不断的从队列中往外推</p>
<pre><code class="language-go">func (d *diskQueue) ioLoop() {
	var dataRead []byte
	var err error
	var count int64
	var r chan []byte

	//开启一个timer，syncTimeout在系统配置里，默认是2秒一次
	syncTicker := time.NewTicker(d.syncTimeout)

	for {
		// SyncEvery是系统配置，默认值是2500
		// 也就是如果现在这段代码中的count的值如果到了2500,则将缓存中的数据保存到磁盘
		if count == d.syncEvery {
			d.needSync = true
		}

		// needSync这个字段如果为true，则将缓存中的数据保存到磁盘
		if d.needSync {
			err = d.sync()
			if err != nil {
				d.logf(ERROR, "DISKQUEUE(%s) failed to sync - %s", d.name, err)
			}
			//同步缓存到磁盘成功，将count重置为0
			count = 0
		}

		//如果队列头和尾中间还有数据，则从头部读取数据
		if (d.readFileNum &lt; d.writeFileNum) || (d.readPos &lt; d.writePos) {
			if d.nextReadPos == d.readPos {
				dataRead, err = d.readOne()
				if err != nil {
					d.logf(ERROR, "DISKQUEUE(%s) reading at %d of %s - %s",
						d.name, d.readPos, d.fileName(d.readFileNum), err)
					d.handleReadError()
					continue
				}
			}
			//这里读取的数据放到readChan这个通道里
			r = d.readChan
		} else {
			r = nil
		}

		select {
		// the Go channel spec dictates that nil channel operations (read or write)
		// in a select are skipped, we set r to d.readChan only when there is data to read
		//看上面的英文注释，如果r为空，则这个分支会被跳过，这是golang的一个特性
		//将读取的消息，丢到d.readChan里面，r.readChan向外部暴露
		case r &lt;- dataRead:
			count++
			// moveForward sets needSync flag if a file is removed
			//moveForward()会删除已经没用的file，这个文件中的数据已经全部被读取了，不在队列头和尾之间了
			d.moveForward()
		case &lt;-d.emptyChan:
			d.emptyResponseChan &lt;- d.deleteAllFiles()
			count = 0
		case dataWrite := &lt;-d.writeChan:
			//如果d.writeChan有写入数据，则将消息数据写入到队列
			count++
			d.writeResponseChan &lt;- d.writeOne(dataWrite)
		case &lt;-syncTicker.C:
			//这里相当于两秒钟同步一次缓存到磁盘
			if count == 0 {
				// avoid sync when there's no activity
				continue
			}
			d.needSync = true
		case &lt;-d.exitChan:
			goto exit
		}
	}

exit:
	d.logf(INFO, "DISKQUEUE(%s): closing ... ioLoop", d.name)
	syncTicker.Stop()
	d.exitSyncChan &lt;- 1
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="nsq源码-nsqd总体流程"><a class="header" href="#nsq源码-nsqd总体流程">nsq源码-nsqd总体流程</a></h1>
<p>看了一阵子nsq源码，出去细节大体的流程基本算是看明白了
下面来总结一下，看下面的图</p>
<p><img src="/images/1808174-20210312153309318-1977366713.png" alt="" /></p>
<p>个人觉得其实只要搞清楚几个Loop，我称为“守护”协程，也就是一直在for... select... 里面跑着不退出的几个关键函数。
看上面的图，有几个呢？</p>
<p>从底层依次往上看</p>
<ol>
<li>
<p>diskqueue.IoLoop()： 我觉得这个第一个要看懂，topic和channel都会用到他来作为磁盘存储消息，关键消息在里面怎么进怎么出，这里也要搞清楚。</p>
</li>
<li>
<p>Topic.MessagePump(): 不断的将topci收到的消息，分发给底下所有的Channel。</p>
</li>
<li>
<p>protocolV2.IOLoop(): 处理客户端通过socket传上来的指令，然后分发处理指令。比如收到PUB指令，将消息丢给topic</p>
</li>
<li>
<p>protocolV2.messagePump(): 不断的将Channel.memoryMsgChan或者diskqueue里面的消息通过socket推给客户端订阅者</p>
</li>
<li>
<p>nsqd.queueScanLoop(): 其实看上面的协程都是成对出现的，也就是消息有进去协程，就应该有消息出来的协程。但是Channel有消息进去的协程，也就是topic的MessagePump这个协程负责将消息给Channel，那么Channel消息出来的协程就是这个nsqd.queueScanLoop()了。他负责将Inflight也就是处理中的消息，推到channel.memoryMsgChan或者diskqueue中。</p>
</li>
</ol>
<p>一个完整的消息进出流程大概就是这样子</p>
<p>客户端生产者 -&gt; protocolV2.IOLoop() 收到消息
-&gt; Topic.PutMessage() 消息传到Topic
-&gt; Topic.MessagePump() 消息传到Channel.InFlight
-&gt; nsqd.queueScanLoop()
-&gt; 消息传到Channel.memoryMsgChan
-&gt; protocolV2.messagePump()
-&gt; 客户端订阅者</p>
<p><em>这里有一个很容易搞晕的地方，就是Channel中放消息其实有两块</em></p>
<pre><code class="language-go">type Channel struct {
	... //这一块是存储和持久化，消息最终是从这里出去
	backend BackendQueue
	memoryMsgChan chan *Message
	
	... //这一块可以理解成一个缓存，意思在处理中消息，消息首先到这里
	deferredMessages map[MessageID]*pqueue.Item
	deferredPQ       pqueue.PriorityQueue
	deferredMutex    sync.Mutex
	inFlightMessages map[MessageID]*Message
	inFlightPQ       inFlightPqueue
	inFlightMutex    sync.Mutex
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="nsq源码-topic"><a class="header" href="#nsq源码-topic">nsq源码-topic</a></h1>
<p>topic的入口在哪里：GetTopic()</p>
<p>GetTopic如果存在则直接返回，不存在则NewTopic()</p>
<p>个人觉得Topic里面有两个重要的变量和一个函数，搞清楚这三个东西就差不多了</p>
<ol>
<li>
<p><strong>memoryMsgChan</strong>： 这是存放消息的内存，就是一个通道，通道的大小MemQueueSize，
默认配置是10000，也就是如果堆积的消息超过10000就会使用磁盘了</p>
</li>
<li>
<p><strong>backend</strong> ：就是diskqueue，这个就是磁盘存储消息的地方了，这个diskqueue一定要搞懂，因为后面channel也会用到这个queue，关于这个diskqueue，请参考：https://www.cnblogs.com/werben/p/14517781.html</p>
</li>
<li>
<p><strong>messagePump</strong> : 这是topic的一个“守护”协程，看源码里的英文注释， <code>messagePump selects over the in-memory and backend queue and writes messages to every channel for this topic</code>，它将topic收到的消息，分发给每个channel。</p>
</li>
</ol>
<pre><code class="language-go">func (t *Topic) messagePump() {
	var msg *Message
	var buf []byte
	var err error
	var chans []*Channel
	var memoryMsgChan chan *Message
	var backendChan &lt;-chan []byte

	// do not pass messages before Start(), but avoid blocking Pause() or GetChannel()
	//这里就是要等到startChan完成后才能往下走，
	for {
		select {
		case &lt;-t.channelUpdateChan:
			continue
		case &lt;-t.pauseChan:
			continue
		case &lt;-t.exitChan:
			goto exit
		case &lt;-t.startChan:
		//也就是要等到topic执行完GetChannel()之后才会接着往下走
		}
		break
	}
	t.RLock()
	//将所有channel通道放在chans中
	for _, c := range t.channelMap {
		chans = append(chans, c)
	}
	t.RUnlock()
	if len(chans) &gt; 0 &amp;&amp; !t.IsPaused() {
		memoryMsgChan = t.memoryMsgChan
		//backendChan就是backend暴露给外部的readChan
		//参考: https://www.cnblogs.com/werben/p/14517781.html
		backendChan = t.backend.ReadChan()
	}

	// main message loop
	//这里是守护协程的主体了，也就是这个for会一直跑
	for {
		select {
		case msg = &lt;-memoryMsgChan:
			//如果topic有收到新消息
		case buf = &lt;-backendChan:
			//如果消息是从diskqueue里来的，还要解码反序列化成msg
			msg, err = decodeMessage(buf)
			if err != nil {
				t.nsqd.logf(LOG_ERROR, "failed to decode message - %s", err)
				continue
			}
		case &lt;-t.channelUpdateChan:
			//如果有新的channel通道
			chans = chans[:0]
			t.RLock()
			for _, c := range t.channelMap {
				chans = append(chans, c)
			}
			t.RUnlock()
			if len(chans) == 0 || t.IsPaused() {
				memoryMsgChan = nil
				backendChan = nil
			} else {
				memoryMsgChan = t.memoryMsgChan
				backendChan = t.backend.ReadChan()
			}
			continue
		case &lt;-t.pauseChan:
			//如果channel通道暂停
			if len(chans) == 0 || t.IsPaused() {
				memoryMsgChan = nil
				backendChan = nil
			} else {
				memoryMsgChan = t.memoryMsgChan
				backendChan = t.backend.ReadChan()
			}
			continue
		case &lt;-t.exitChan:
			goto exit
		}

		//遍历每一个channel通道，将消息投递过去
		for i, channel := range chans {
			chanMsg := msg
			// copy the message because each channel
			// needs a unique instance but...
			// fastpath to avoid copy if its the first channel
			// (the topic already created the first copy)
			if i &gt; 0 {
				chanMsg = NewMessage(msg.ID, msg.Body)
				chanMsg.Timestamp = msg.Timestamp
				chanMsg.deferred = msg.deferred
			}
			if chanMsg.deferred != 0 {
				//如果是延时消息则将延时消息丢给channel
				channel.PutMessageDeferred(chanMsg, chanMsg.deferred)
				continue
			}
			//将消息则将延时消息丢给channel
			err := channel.PutMessage(chanMsg)
			if err != nil {
				t.nsqd.logf(LOG_ERROR,
					"TOPIC(%s) ERROR: failed to put msg(%s) to channel(%s) - %s",
					t.name, msg.ID, channel.name, err)
			}
		}
	}

exit:
	t.nsqd.logf(LOG_INFO, "TOPIC(%s): closing ... messagePump", t.name)
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="eventbus"><a class="header" href="#eventbus">EventBus</a></h1>
<p>EventBus 是一个轻量级的事件发布/订阅框架，支持同步和异步发布消息，它可以简化 Go 协程之间的通信。</p>
<h2 id="安装"><a class="header" href="#安装">安装</a></h2>
<p>确保计算机上已安装 Go（版本 1.18+）。在终端中输入以下命令：</p>
<p><code>go get github.com/werbenhu/eventbus</code></p>
<p><em>在项目中导入包</em></p>
<pre><code class="language-go">import (
	"github.com/werbenhu/eventbus"
)
</code></pre>
<h2 id="eventbus-是什么"><a class="header" href="#eventbus-是什么">EventBus 是什么？</a></h2>
<p>EventBus同时支持同步和异步的方式发布消息。EventBus使用一个Copy-On-Write的map管理handler和topic，所以不建议在有大量频繁的订阅和取消订阅的业务场景中使用。</p>
<h4 id="异步的方式"><a class="header" href="#异步的方式">异步的方式</a></h4>
<p>在EventBus里，每个主题对应一个通道。<code>Publish()</code> 方法将消息推送到通道，<code>Subscribe(</code>) 方法中的handler将处理从通道出来的消息。如果要使用带缓冲的EventBus，可以使用 <code>eventbus.NewBuffered(bufferSize int)</code> 方法创建带缓冲的EventBus，这样会为每个topic都创建一个带缓冲的channel。</p>
<h4 id="同步的方式"><a class="header" href="#同步的方式">同步的方式</a></h4>
<p>同步的方式下EventBus不使用channel，而是通过直接调用handler将消息传递给订阅者。如果想同步的方式发布消息，使用eventbus.PublishSync()函数即可。</p>
<h3 id="eventbus-示例"><a class="header" href="#eventbus-示例">EventBus 示例</a></h3>
<pre><code class="language-go">package main

import (
	"fmt"
	"time"

	"github.com/werbenhu/eventbus"
)

func handler(topic string, payload int) {
	fmt.Printf("topic:%s, payload:%d\n", topic, payload)
}

func main() {
	bus := eventbus.New()

	// Subscribe() 订阅一个主题，如果handler不是函数则返回错误。
	// handler必须有两个参数：第一个参数必须是字符串类型，
	// handler的第二个参数类型必须与 `Publish()` 中的 payload 类型一致。
	bus.Subscribe("testtopic", handler)

	// 异步方式发布消息
	bus.Publish("testtopic", 100)

	// 同步方式发布消息
	bus.PublishSync("testtopic", 200)

	// 订阅者接收消息。为了确保订阅者可以接收完所有消息的异步消息，这里在取消订阅之前给了一点延迟。
	time.Sleep(time.Millisecond)
	bus.Unsubscribe("testtopic", handler)
	bus.Close()
}
</code></pre>
<h3 id="使用全局的eventbus单例对象"><a class="header" href="#使用全局的eventbus单例对象">使用全局的EventBus单例对象</a></h3>
<p>为了更方便的使用EventBus, 这里有一个全局的EventBus单例对象，使用<code>eventbus.InitSingleton() </code>初始化这个单例对象，这个对象内部的channel是无缓冲的，直接使用<code>eventbus.Subscribe()</code>,<code>eventbus.Publish()</code>,<code>eventbus.Unsubscribe()</code>，将会调用该单例对象对应的方法。</p>
<pre><code class="language-go">func handler(topic string, payload int) {
	fmt.Printf("topic:%s, payload:%d\n", topic, payload)
}

func main() {

	// 初始化单例对象
	eventbus.InitSingleton()

	// eventbus.Subscribe() 将调用全局单例singleton.Subscribe()方法
	eventbus.Subscribe("testtopic", handler)

	var wg sync.WaitGroup
	wg.Add(1)
	go func() {
		// 异步方式发布消息
		for i := 0; i &lt; 100; i++ {
			// 调用全局单例singleton.Publish()方法
			eventbus.Publish("testtopic", i)
		}
		// 同步方式发布消息
		for i := 100; i &lt; 200; i++ {
			// 调用全局单例singleton.PublishSync()方法
			eventbus.PublishSync("testtopic", i)
		}
		wg.Done()
	}()
	wg.Wait()

	time.Sleep(time.Millisecond)
	// eventbus.Unsubscribe() 将调用全局单例singleton.Unsubscribe()方法
	eventbus.Unsubscribe("testtopic", handler)

	// eventbus.Close() 将调用全局单例singleton.Close()方法
	eventbus.Close()
}
</code></pre>
<h2 id="使用pipe代替channel"><a class="header" href="#使用pipe代替channel">使用Pipe代替Channel</a></h2>
<p>Pipe 将通道封装成泛型对象，泛型参数对应channle里的类型，这里没有主题的概念。
<code>eventbus.NewPipe[T]()</code> 等价于 <code>make(chan T)</code>,发布者发布消息，订阅者接收消息，可以使用 <code>Pipe.Publish()</code> 方法代替 <code>chan &lt;-</code>，使用 <code>Pipe.Subscribe()</code> 方法代替 <code>&lt;-chan</code>。如果有多个订阅者，则每个订阅者将接收到发布出来的每一条消息。</p>
<p>如果要使用带缓冲的通道，可以使用 <code>eventbus.NewBufferedPipe[T](bufferSize int)</code> 方法创建带缓冲的管道。Pipe同样支持同步和异步的方式发布消息。如果需要使用同步的方式，请调用Pipe.PublishSync()。</p>
<h4 id="pipe-示例"><a class="header" href="#pipe-示例">Pipe 示例</a></h4>
<pre><code class="language-go">func handler1(val string) {
	fmt.Printf("handler1 val:%s\n", val)
}

func handler2(val string) {
	fmt.Printf("handler2 val:%s\n", val)
}

func main() {
	pipe := eventbus.NewPipe[string]()
	pipe.Subscribe(handler1)
	pipe.Subscribe(handler2)

	var wg sync.WaitGroup
	wg.Add(1)
	go func() {
		for i := 0; i &lt; 100; i++ {
			pipe.Publish(strconv.Itoa(i))
		}
		for i := 100; i &lt; 200; i++ {
			pipe.PublishSync(strconv.Itoa(i))
		}
		wg.Done()
	}()
	wg.Wait()

	time.Sleep(time.Millisecond)
	pipe.Unsubscribe(handler1)
	pipe.Unsubscribe(handler2)
	pipe.Close()
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="定义"><a class="header" href="#定义">定义</a></h2>
<p>写入时复制（英语：<code>Copy-On-Write</code>，简称COW）是一种计算机程序设计领域的优化策略。其核心思想是，如果有多个调用者（callers）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。这过程对其他的调用者都是透明的。此作法主要的优点是如果调用者没有修改该资源，就不会有副本（private copy）被创建，因此多个调用者只是读取操作时可以共享同一份资源。<em>Copy-On-Write策略用于读多写少的并发场景。</em>
上面的定义估计第一次看都有点蒙，我这里举一个实际例子，就很好理解了。</p>
<h2 id="代码1---并发出错"><a class="header" href="#代码1---并发出错">代码1 - 并发出错</a></h2>
<pre><code class="language-Go">package main

import (
	"fmt"
	"strconv"
)

type CowMap map[int]string

func (c *CowMap) Set(key int, value string) {
	(*c)[key] = value
}

func (c *CowMap) Get(key int) string {
	return (*c)[key]
}

func readLoop(c *CowMap) {
	for {
		fmt.Println(c.Get(3))
	}
}

func writeLoop(c *CowMap) {
	for i := 0; i &lt; 10000000; i++ {
		//修改map的值
		c.Set(3, "werben-"+strconv.Itoa(i))
	}
}

func main() {
	c := make(CowMap)
	c.Set(1, "a")
	c.Set(2, "b")
	c.Set(3, "c")

	go readLoop(&amp;c)
	writeLoop(&amp;c)
}
</code></pre>
<p>运行上面的代码，会出错：<code>fatal error: concurrent map read and map write</code>.
因为有两个协程(主协程<code>writeLoop</code>和<code>readLoop</code>协程)同时读写同一个map，而这个map不是线程安全，所以会导致上面的出错。</p>
<h2 id="代码2-引入读写锁"><a class="header" href="#代码2-引入读写锁">代码2-引入读写锁</a></h2>
<p>为了解决上面的问题我们引入读写锁</p>
<pre><code class="language-go">package main

import (
	"fmt"
	"strconv"
	"sync"
)

//读写锁
var mu sync.RWMutex

type CowMap map[int]string

func (c *CowMap) Set(key int, value string) {
	(*c)[key] = value
}

func (c *CowMap) Get(key int) string {
	return (*c)[key]
}

func readLoop(c *CowMap) {
	for {
		//读的时候上读锁
		mu.RLock()
		fmt.Println(c.Get(3))
		mu.RUnlock()
	}
}

func writeLoop(c *CowMap) {
	for i := 0; i &lt; 10000000; i++ {
		//写的时候上写锁
		mu.Lock()
		c.Set(3, "werben-"+strconv.Itoa(i))
		mu.Unlock()
	}
}

func main() {
	c := make(CowMap)
	c.Set(1, "a")
	c.Set(2, "b")
	c.Set(3, "c")

	go readLoop(&amp;c)
	writeLoop(&amp;c)
}
运行上面的代码，不会报错了。
如果我们将writeLoop()改成如下，每5秒写一次。
func writeLoop(c *CowMap) {
	for i := 0; i &lt; 10000000; i++ {
		//每隔5s写一次
		time.Sleep(time.Second*5)
		//写的时候上写锁
		mu.Lock()
		c.Set(3, "werben-"+strconv.Itoa(i))
		mu.Unlock()
	}
}
</code></pre>
<p>我们看下读写锁的特性：</p>
<ul>
<li>读锁不能阻塞读锁</li>
<li>读锁需要阻塞写锁，直到所有读锁都释放</li>
<li>写锁需要阻塞读锁，直到所有写锁都释放</li>
<li>写锁需要阻塞写锁</li>
</ul>
<p>只是每隔5秒写一次，但是上面的读锁还是一直不断的上锁解锁，这个在没有写数据的时候，其实都是没有意义的。如果时间更长，比如1天才修改一次，读锁浪费了大量的无用资源。
这时候，如果我们用copy-on-write策略，代码如下：</p>
<h2 id="代码3---copy-on-write实现"><a class="header" href="#代码3---copy-on-write实现">代码3 - Copy-On-Write实现</a></h2>
<pre><code class="language-go">package main

import (
	"fmt"
	"strconv"
	"sync"
	"sync/atomic"
)

type tmap map[int]string

type CowMap struct {
	mu   sync.Mutex
	data atomic.Value
}

func NewCowMap() *CowMap {
	m := make(tmap)
	c := &amp;CowMap{}
	c.data.Store(m)
	return c
}

func (c *CowMap) clone() tmap {
	m := make(tmap)
	for k, v := range c.data.Load().(tmap) {
		m[k] = v
	}
	return m
}

func (c *CowMap) Get(key int) (value string, ok bool) {
	value, ok = c.data.Load().(tmap)[key]
	return
}

func (c *CowMap) Set(key int, value string) {
	c.mu.Lock()
	defer c.mu.Unlock()

	//写之前，先拷贝一个副本
	copy := c.clone()
	//修改副本
	copy[key] = value
	//修改副本数据后，将副本转正
	c.data.Store(copy)
}

func readLoop(c *CowMap) {
	for {
		fmt.Println(c.Get(3))
	}
}

func writeLoop(c *CowMap) {
	for i := 0; i &lt; 10000000; i++ {
		c.Set(3, "werben-"+strconv.Itoa(i))
	}
}

func main() {
	c := NewCowMap()
	c.Set(1, "a")
	c.Set(2, "b")
	c.Set(3, "c")

	go readLoop(c)
	writeLoop(c)
}
</code></pre>
<p>在写入之前先拷贝一个副本，对副本进行修改，副本修改之后，将副本转正。这时多个调用者只是读取时就可以不需要上锁了。</p>
<h2 id="缺点"><a class="header" href="#缺点">缺点</a></h2>
<ul>
<li>内存占用问题
因为Copy-On-Write的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存。</li>
<li>数据一致性问题
Copy-On-Write策略只能保证数据的最终一致性，不能保证数据的实时一致性。写入数据之后，不能保证马上读取到最新的数据。</li>
</ul>
<h2 id="实际应用"><a class="header" href="#实际应用">实际应用</a></h2>
<p>我们来看下在golang官方库btree里是怎么使用Copy-On-Write策略的
这个库的官方地址在这里，有兴趣的可以去读一读：https://github.com/google/btree
首先在BTree定义里，定义了一个copyOnWriteContext, cow里实际就是保存了一个*node的数组，
然后每个node里面也保存了一份cow。</p>
<pre><code class="language-go">type BTree struct {
	degree int
	length int
	root   *node
	cow    *copyOnWriteContext
}
...

type copyOnWriteContext struct {
	freelist *FreeList
}

...
type FreeList struct {
	mu       sync.Mutex
	freelist []*node
}


type node struct {
	items    items
	children children
	cow      *copyOnWriteContext
}
BTree有一个Clone方法， 可以看到虽然clone出来一个新的cow2，但是cow1和cow2里指向的freelist却还是都是同一个地址(freelist)。也就是如果只是读取Clone()出来的新BTree，跟原先的是同一份freelist，freelist里面的node如果不修改，则都可以不需要重新拷贝。
func (t *BTree) Clone() (t2 *BTree) {
	// Create two entirely new copy-on-write contexts.
	// This operation effectively creates three trees:
	//   the original, shared nodes (old b.cow)
	//   the new b.cow nodes
	//   the new out.cow nodes
	cow1, cow2 := *t.cow, *t.cow
	out := *t
	t.cow = &amp;cow1
	out.cow = &amp;cow2
	return &amp;out
}
当需要修改freelist里面的Node的时候
func (t *BTree) ReplaceOrInsert(item Item) Item {
	if item == nil {
		panic("nil item being added to BTree")
	}
	if t.root == nil {
		t.root = t.cow.newNode()
		t.root.items = append(t.root.items, item)
		t.length++
		return nil
	} else {
		//这里判断一下需不需要重新拷贝node
		t.root = t.root.mutableFor(t.cow)
		if len(t.root.items) &gt;= t.maxItems() {
			item2, second := t.root.split(t.maxItems() / 2)
			oldroot := t.root
			t.root = t.cow.newNode()
			t.root.items = append(t.root.items, item2)
			t.root.children = append(t.root.children, oldroot, second)
		}
	}
	out := t.root.insert(item, t.maxItems())
	if out == nil {
		t.length++
	}
	return out
}

//这里的逻辑就是判断一下，是否需要重新复制node，并修改其值
func (n *node) mutableFor(cow *copyOnWriteContext) *node {
	//判断一下，当前node的cow和BTree里面的cow是不是同一个
	if n.cow == cow {
		//如果不是Clone()出来的BTree，则不涉及到拷贝,
		//直接返回当前node,
		return n
	}

	//如果是Clone()出来的新BTree，新的BTree里的cow是变动了的，
	//这里要修改这个node,所以这个node的数据需要重新拷贝一份。
	out := cow.newNode()
	if cap(out.items) &gt;= len(n.items) {
		out.items = out.items[:len(n.items)]
	} else {
		out.items = make(items, len(n.items), cap(n.items))
	}
	copy(out.items, n.items)
	// Copy children
	if cap(out.children) &gt;= len(n.children) {
		out.children = out.children[:len(n.children)]
	} else {
		out.children = make(children, len(n.children), cap(n.children))
	}
	copy(out.children, n.children)
	return out
}
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
